include: 'common.snakemake'

import shutil

root_dir=config.get('root_dir')
data_dir=config.get('data_dir')
output_dir=config.get('output_dir')

rule bwa_map1:
    input:
        fastq1=config.get('data_dir') + '/fastq/{sample_id}_1.fastq'
    output:
        bam1='{output_dir}/bwa_map/{sample_id}_1.bam'
    params:
        bwa_index=config.get('genome_dir') + '/genome_index/bwa/genome'
    threads:
        config.get('threads_mapping')
    conda:
        'envs/dna-seq.yaml'
    log:
        '{output_dir}/log/bwa_map/{sample_id}_1.log'
    shell:
        '''
            bwa aln -t {threads} -f {output.bam1} {params.bwa_index} {input.fastq1} > {log} 2>&1
        '''

rule bwa_map2:
    input:
        fastq2=config.get('data_dir') + '/fastq/{sample_id}_2.fastq'
    output:
        bam2='{output_dir}/bwa_map/{sample_id}_2.bam'
    params:
        bwa_index=config.get('genome_dir') + '/genome_index/bwa/genome'
    threads:
        config.get('threads_mapping')
    conda:
        'envs/dna-seq.yaml'
    log:
        '{output_dir}/log/bwa_map/{sample_id}_2.log'
    shell:
        '''
            bwa aln -t {threads} -f {output.bam2} {params.bwa_index} {input.fastq2} > {log} 2>&1
        '''

rule sam:
    input:
        fastq1=config.get('data_dir') + '/fastq/{sample_id}_1.fastq',
        fastq2=config.get('data_dir') + '/fastq/{sample_id}_2.fastq',
        bam1='{output_dir}/bwa_map/{sample_id}_1.bam',
        bam2='{output_dir}/bwa_map/{sample_id}_2.bam'
    output:
        sam_file='{output_dir}/sam/{sample_id}.sam'
    params:
        bwa_index=config.get('genome_dir') + '/genome_index/bwa/genome'
    threads:
        config.get('threads_mapping')
    conda:
        'envs/dna-seq.yaml'
    log:
        sam_log='{output_dir}/log/sam/{sample_id}.log'
    shell:
        '''
            bwa sampe -f {output.sam_file} {params.bwa_index} {input.bam1} {input.bam2} {input.fastq1} {input.fastq2} > {log.sam_log} 2>&1
        '''

rule sorted_bam:
    input:
        sam_file='{output_dir}/sam/{sample_id}.sam'
    output:
        sorted_bam='{output_dir}/sorted_bam/{sample_id}.bam'
    threads:
        config.get('threads_mapping')
    conda:
        'envs/dna-seq.yaml'
    log:
        '{output_dir}/log/sorted_bam/{sample_id}.log'
    shell:
        '''
            samtools view -h {input.sam_file} | samtools sort -@ {threads} -o {output.sorted_bam} > {log} 2>&1
        '''

rule dedup:
    input:
        sorted_bam='{output_dir}/sorted_bam/{sample_id}.bam'
    output:
        dedup_bam='{output_dir}/dedup_bam/{sample_id}_dedup.bam',
        metrics_picard='{output_dir}/dedup_bam/{sample_id}.dedup.txt'
    params:
        metrics_picard_file=''
    threads:
        config.get('threads_mapping')
    conda:
        'envs/dna-seq.yaml'
    log:
        '{output_dir}/log/dedup_bam/{sample_id}.log'
    shell:
        '''
            picard MarkDuplicates -INPUT {input.sorted_bam} -OUTPUT {output.dedup_bam} \
                -METRICS_FILE {output.metrics_picard} \
                -VALIDATION_STRINGENCY LENIENT -ASSUME_SORTED true -REMOVE_DUPLICATES true > {log} 2>&1
        '''

rule call_peak_using_danpos:
    input:
        dedup_bam='{output_dir}/dedup_bam/{sample_id}_dedup.bam'
    output:
        peak_xls='{output_dir}/peaks/{sample_id}/pooled/{sample_id}.xls',
        peak_wig='{output_dir}/peaks/{sample_id}/pooled/{sample_id}.wig'
    threads:
        config.get('threads_mapping')
    params:
        peak_file_dir='{output_dir}/peaks/{sample_id}',
        peak_xls_tmp='{output_dir}_dedup_bam_{sample_id}_dedup.smooth.positions.xls',
        peak_wig_tmp='{output_dir}_dedup_bam_{sample_id}_dedup.smooth.wig'
    conda:
        'envs/danpos.yaml'
    log:
        '{output_dir}/log/call_peak_using_danpos/{sample_id}.log'
    shell:
        '''
            danpos.py dpos {input.dedup_bam} -o {params.peak_file_dir} > {log} 2>&1 ; \
            mv {params.peak_file_dir}/pooled/{params.peak_xls_tmp} {output.peak_xls} ; \
            mv {params.peak_file_dir}/pooled/{params.peak_wig_tmp} {output.peak_name}
        '''

rule peak_to_bed:
    input:
        peak_wig='{output_dir}/peaks/{sample_id}/pooled/{sample_id}.wig'
    output:
        bed_file='{output_dir}/bed/{sample_id}.bed'
    threads:
        1
    conda:
        'envs/dna-seq.yaml'
    log:
        '{output_dir}/log/peak_to_bed/{sample_id}.log'
    shell:
        '''
            wig2bed < {input.pead_wig} > {output.bed_file} > {log} 2>&1
        '''